{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94m1JjnW-Km6",
        "outputId": "e7ee7590-0fbe-4a74-f456-e8416924af97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Original data size: 10664\n",
            "[WARNING] sum_of_requested(1090) > n_total(1000). Will expand total sample size to 1090.\n",
            "[INFO] Final sample size: 1090 (target was 1090)\n",
            "[INFO] Sample distribution:\n",
            "predicted_cat\n",
            "Other                 503\n",
            "Express Entry         164\n",
            "PGWP                   96\n",
            "Student Permit         90\n",
            "Work Permit            87\n",
            "Family Sponsorship     50\n",
            "PNP                    50\n",
            "Refugee                50\n",
            "Name: count, dtype: int64\n",
            "[DONE] 'sample_for_manual_label.csv' is ready for manual labeling.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define 8 categories with keywords\n",
        "category_keywords = {\n",
        "    \"PGWP\": [\n",
        "        \"pgwp\", \"post graduation work permit\"\n",
        "    ],\n",
        "    \"Express Entry\": [\n",
        "        \"express entry\", \"crs score\", \"ita\", \"ee profile\", \"federal skilled worker\", \"cec\"\n",
        "    ],\n",
        "    \"Student Permit\": [\n",
        "        \"study permit\", \"student visa\", \"dli\"\n",
        "    ],\n",
        "    \"PNP\": [\n",
        "        \"pnp\", \"provincial nominee\", \"oinp\", \"bc pnp\", \"mpnp\", \"sinp\"\n",
        "    ],\n",
        "    \"Work Permit\": [\n",
        "        \"lmia\", \"closed work permit\", \"gts\", \"global talent stream\",\n",
        "        \"work permit\", \"intra-company transfer\", \"lmia-exempt\"\n",
        "    ],\n",
        "    \"Family Sponsorship\": [\n",
        "        \"spousal sponsorship\", \"common law sponsorship\",\n",
        "        \"parents sponsorship\", \"family sponsorship\"\n",
        "    ],\n",
        "    \"Refugee\": [\n",
        "        \"refugee\", \"asylum\", \"protected person\", \"h&c\"\n",
        "    ],\n",
        "    \"Other\":\n",
        "}\n",
        "\n",
        "def predict_category_by_keywords(text, cat_keywords):\n",
        "    \"\"\"\n",
        "    Simple heuristic:\n",
        "      - For each category except 'Other', check if any keyword appears in text.\n",
        "      - If found, return that category immediately.\n",
        "      - If none found, return 'Other'.\n",
        "    \"\"\"\n",
        "    text_lower = str(text).lower()\n",
        "    for cat, kw_list in cat_keywords.items():\n",
        "        if cat == \"Other\":\n",
        "            continue\n",
        "        for kw in kw_list:\n",
        "            if kw in text_lower:\n",
        "                return cat\n",
        "    return \"Other\"\n",
        "\n",
        "def guess_categories(df, text_col=\"clean_text\"):\n",
        "    \"\"\"\n",
        "    Apply the simple keyword-based guess for each row,\n",
        "    store the result in df[\"predicted_cat\"].\n",
        "    \"\"\"\n",
        "    df[\"predicted_cat\"] = df[text_col].apply(\n",
        "        lambda x: predict_category_by_keywords(x, category_keywords)\n",
        "    )\n",
        "    return df\n",
        "\n",
        "def stratified_sample_with_min_quota(df, group_col, n_total=1000, min_per_cat=None):\n",
        "    \"\"\"\n",
        "    Stratified sampling with optional minimum quota per category.\n",
        "\n",
        "    - If min_per_cat is given as a dict like {\"Refugee\": 50, \"PNP\": 50},\n",
        "      then those categories will get at least that many rows in the sample.\n",
        "    - If sum_of_requested > n_total, we automatically expand n_total\n",
        "      to sum_of_requested to meet min quotas.\n",
        "    - The final sample is returned (shuffled).\n",
        "    \"\"\"\n",
        "\n",
        "    group_counts = df[group_col].value_counts()\n",
        "    total_count = group_counts.sum()\n",
        "\n",
        "    cat_sampling_numbers = {}\n",
        "    sum_of_requested = 0\n",
        "\n",
        "\n",
        "    for cat_value, cat_count in group_counts.items():\n",
        "        ratio = cat_count / total_count\n",
        "        n_group = int(round(ratio * n_total))\n",
        "\n",
        "\n",
        "        if min_per_cat and cat_value in min_per_cat:\n",
        "            min_q = min_per_cat[cat_value]\n",
        "            if n_group < min_q:\n",
        "                n_group = min_q\n",
        "\n",
        "        subset_size = len(df[df[group_col] == cat_value])\n",
        "        n_group_final = min(n_group, subset_size)\n",
        "        cat_sampling_numbers[cat_value] = n_group_final\n",
        "        sum_of_requested += n_group_final\n",
        "\n",
        "\n",
        "    if sum_of_requested > n_total:\n",
        "        print(f\"[WARNING] sum_of_requested({sum_of_requested}) > n_total({n_total}). \"\n",
        "              f\"Will expand total sample size to {sum_of_requested}.\")\n",
        "        n_total = sum_of_requested\n",
        "\n",
        "    all_samples = []\n",
        "    for cat_value, n_req in cat_sampling_numbers.items():\n",
        "        subset_df = df[df[group_col] == cat_value]\n",
        "        if len(subset_df) <= n_req:\n",
        "            sampled_df = subset_df\n",
        "        else:\n",
        "            sampled_df = subset_df.sample(n_req, random_state=42)\n",
        "        all_samples.append(sampled_df)\n",
        "\n",
        "    final_sample = pd.concat(all_samples).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    print(f\"[INFO] Final sample size: {len(final_sample)} (target was {n_total})\")\n",
        "    print(\"[INFO] Sample distribution:\")\n",
        "    print(final_sample[group_col].value_counts())\n",
        "    return final_sample\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv(\"/content/cleaned_merged_data_Final.csv\")\n",
        "    print(\"[INFO] Original data size:\", len(df))\n",
        "\n",
        "    text_col = \"clean_text\"\n",
        "\n",
        "    df_with_guess = guess_categories(df, text_col=text_col)\n",
        "\n",
        "\n",
        "    min_per_cat = {\n",
        "        \"Refugee\": 50,\n",
        "        \"Family Sponsorship\": 50,\n",
        "        \"PNP\": 50\n",
        "    }\n",
        "\n",
        "    df_sample = stratified_sample_with_min_quota(\n",
        "        df_with_guess,\n",
        "        group_col=\"predicted_cat\",\n",
        "        n_total=1000,  # desired total\n",
        "        min_per_cat=min_per_cat\n",
        "    )\n",
        "\n",
        "    df_sample.to_csv(\"sample_for_manual_label.csv\", index=False)\n",
        "    print(\"[DONE] 'sample_for_manual_label.csv' is ready for manual labeling.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Define 8 categories with keywords\n",
        "category_keywords = {\n",
        "    \"PGWP\": [\n",
        "        \"pgwp\", \"post graduation work permit\"\n",
        "    ],\n",
        "    \"Express Entry\": [\n",
        "        \"express entry\", \"crs score\", \"ita\", \"ee profile\", \"federal skilled worker\", \"cec\"\n",
        "    ],\n",
        "    \"Student Permit\": [\n",
        "        \"study permit\", \"student visa\", \"dli\"\n",
        "    ],\n",
        "    \"PNP\": [\n",
        "        \"pnp\", \"provincial nominee\", \"oinp\", \"bc pnp\", \"mpnp\", \"sinp\"\n",
        "    ],\n",
        "    \"Work Permit\": [\n",
        "        \"lmia\", \"closed work permit\", \"gts\", \"global talent stream\",\n",
        "        \"work permit\", \"intra-company transfer\", \"lmia-exempt\"\n",
        "    ],\n",
        "    \"Family Sponsorship\": [\n",
        "        \"spousal sponsorship\", \"common law sponsorship\",\n",
        "        \"parents sponsorship\", \"family sponsorship\"\n",
        "    ],\n",
        "    \"Refugee\": [\n",
        "        \"refugee\", \"asylum\", \"protected person\", \"h&c\"\n",
        "    ],\n",
        "    \"Other\": []\n",
        "}\n",
        "\n",
        "def predict_category_by_keywords(text, cat_keywords):\n",
        "    \"\"\"\n",
        "    Simple heuristic:\n",
        "     - For each category except 'Other', check if any keyword appears in text.\n",
        "     - If matched, return that category.\n",
        "     - Otherwise return 'Other'.\n",
        "    \"\"\"\n",
        "    text_lower = str(text).lower()\n",
        "    for cat, kw_list in cat_keywords.items():\n",
        "        if cat == \"Other\":\n",
        "            continue\n",
        "        for kw in kw_list:\n",
        "            if kw in text_lower:\n",
        "                return cat\n",
        "    return \"Other\"\n",
        "\n",
        "def guess_categories(df, text_col=\"clean_text\"):\n",
        "    \"\"\"\n",
        "    Apply the simple keyword-based guess for each row\n",
        "    and store the result in df[\"predicted_cat\"].\n",
        "    \"\"\"\n",
        "    df[\"predicted_cat\"] = df[text_col].apply(\n",
        "        lambda x: predict_category_by_keywords(x, category_keywords)\n",
        "    )\n",
        "    return df\n",
        "\n",
        "def stratified_sample_with_min_quota(df, group_col, n_total=1000, min_per_cat=None):\n",
        "    \"\"\"\n",
        "    Stratified sampling with optional minimum quota per category.\n",
        "\n",
        "    - If min_per_cat is a dict like {\"Refugee\": 50, \"PNP\": 50},\n",
        "      then those categories will get at least that many rows in the sample.\n",
        "    - If sum_of_requested > n_total, we automatically expand n_total\n",
        "      to sum_of_requested to meet minimum quotas.\n",
        "    - The final sample is returned (shuffled).\n",
        "    \"\"\"\n",
        "    group_counts = df[group_col].value_counts()\n",
        "    total_count = group_counts.sum()\n",
        "\n",
        "    cat_sampling_numbers = {}\n",
        "    sum_of_requested = 0\n",
        "\n",
        "    for cat_value, cat_count in group_counts.items():\n",
        "        ratio = cat_count / total_count\n",
        "        n_group = int(round(ratio * n_total))\n",
        "\n",
        "        if min_per_cat and cat_value in min_per_cat:\n",
        "            min_q = min_per_cat[cat_value]\n",
        "            if n_group < min_q:\n",
        "                n_group = min_q\n",
        "\n",
        "        subset_size = len(df[df[group_col] == cat_value])\n",
        "        n_group_final = min(n_group, subset_size)\n",
        "        cat_sampling_numbers[cat_value] = n_group_final\n",
        "        sum_of_requested += n_group_final\n",
        "\n",
        "    if sum_of_requested > n_total:\n",
        "        print(f\"[WARNING] sum_of_requested({sum_of_requested}) > n_total({n_total}). \"\n",
        "              f\"Will expand total sample size to {sum_of_requested}.\")\n",
        "        n_total = sum_of_requested\n",
        "\n",
        "    all_samples = []\n",
        "    for cat_value, n_req in cat_sampling_numbers.items():\n",
        "        subset_df = df[df[group_col] == cat_value]\n",
        "        if len(subset_df) <= n_req:\n",
        "            sampled_df = subset_df\n",
        "        else:\n",
        "            sampled_df = subset_df.sample(n_req, random_state=42)\n",
        "        all_samples.append(sampled_df)\n",
        "\n",
        "    final_sample = pd.concat(all_samples).sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "    print(f\"[INFO] Final sample size: {len(final_sample)} (target was {n_total})\")\n",
        "    print(\"[INFO] Sample distribution:\")\n",
        "    print(final_sample[group_col].value_counts())\n",
        "    return final_sample\n",
        "\n",
        "def main():\n",
        "    df = pd.read_csv(\"/content/cleaned_merged_data_Final.csv\")\n",
        "    print(\"[INFO] Original data size:\", len(df))\n",
        "\n",
        "    text_col = \"clean_text\"\n",
        "\n",
        "    # 1A) auto-guess categories\n",
        "    df_with_guess = guess_categories(df, text_col=text_col)\n",
        "\n",
        "    # 1B) stratified sampling ~1000 rows\n",
        "    min_per_cat = {\n",
        "        \"Refugee\": 50,\n",
        "        \"Family Sponsorship\": 50,\n",
        "        \"PNP\": 50\n",
        "    }\n",
        "\n",
        "    df_sample = stratified_sample_with_min_quota(\n",
        "        df_with_guess,\n",
        "        group_col=\"predicted_cat\",\n",
        "        n_total=1000,\n",
        "        min_per_cat=min_per_cat\n",
        "    )\n",
        "\n",
        "    df_sample.to_csv(\"sample_for_manual_label.csv\", index=False)\n",
        "    print(\"[DONE] 'sample_for_manual_label.csv' is ready for manual labeling (~1000 rows).\")\n",
        "\n",
        "    # Supplement 50 Express Entry rows\n",
        "    # We want additional 50 'Express Entry' posts that are not in df_sample.\n",
        "\n",
        "    df_used = df_sample\n",
        "    print(f\"[INFO] Already used {len(df_used)} rows for the main sample.\")\n",
        "\n",
        "    df_remaining = df_with_guess[~df_with_guess[text_col].isin(df_used[text_col])]\n",
        "    print(f\"[INFO] Remaining rows after removing used: {len(df_remaining)}\")\n",
        "\n",
        "    df_express = df_remaining[df_remaining[\"predicted_cat\"] == \"Express Entry\"]\n",
        "    print(f\"[INFO] Found {len(df_express)} rows predicted as Express Entry in the remainder.\")\n",
        "\n",
        "    num_needed = 50\n",
        "    if len(df_express) >= num_needed:\n",
        "        df_express_supp = df_express.sample(num_needed, random_state=42)\n",
        "    else:\n",
        "        df_express_supp = df_express\n",
        "\n",
        "    df_express_supp.to_csv(\"supplement_express_entry.csv\", index=False)\n",
        "    print(f\"[DONE] 'supplement_express_entry.csv' created with {len(df_express_supp)} rows for extra Express Entry labeling.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E-7Ita-XSmAH",
        "outputId": "87c2b0b5-0b57-46fd-dd48-f005a19372e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[INFO] Original data size: 10664\n",
            "[WARNING] sum_of_requested(1090) > n_total(1000). Will expand total sample size to 1090.\n",
            "[INFO] Final sample size: 1090 (target was 1090)\n",
            "[INFO] Sample distribution:\n",
            "predicted_cat\n",
            "Other                 503\n",
            "Express Entry         164\n",
            "PGWP                   96\n",
            "Student Permit         90\n",
            "Work Permit            87\n",
            "Family Sponsorship     50\n",
            "PNP                    50\n",
            "Refugee                50\n",
            "Name: count, dtype: int64\n",
            "[DONE] 'sample_for_manual_label.csv' is ready for manual labeling (~1000 rows).\n",
            "[INFO] Already used 1090 rows for the main sample.\n",
            "[INFO] Remaining rows after removing used: 9540\n",
            "[INFO] Found 1583 rows predicted as Express Entry in the remainder.\n",
            "[DONE] 'supplement_express_entry.csv' created with 50 rows for extra Express Entry labeling.\n"
          ]
        }
      ]
    }
  ]
}